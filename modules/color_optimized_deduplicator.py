"""
Color-Optimized Memory-Efficient Deduplication Pipeline

This module implements an enhanced deduplication approach that uses color-based pre-grouping
to significantly reduce the problem size before applying the full deduplication pipeline.

Key improvements:
1. Color-based pre-grouping using MiniBatchKMeans clustering
2. Reduced computational complexity from O(n¬≤) to O(m¬≤) per subgroup
3. Better scalability for 3M+ images
4. Adaptive thresholds based on color similarity
"""

import os
import time
import logging
import threading
from typing import List, Dict, Tuple, Any, Optional
import numpy as np
from tqdm import tqdm
import gc
import cv2
from sklearn.cluster import MiniBatchKMeans
from collections import defaultdict

from .feature_cache import BoundedFeatureCache
from .memory_efficient_deduplication import MemoryEfficientDeduplicator
from .feature_extraction import FeatureExtractor

logger = logging.getLogger(__name__)


class ColorOptimizedDeduplicator(MemoryEfficientDeduplicator):
    """
    Color-optimized deduplicator that uses color-based pre-grouping
    to improve scalability for large datasets (3M+ images).
    """
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.color_clusters = 2000  # Number of color clusters for pre-grouping
        self.batch_size = 1000      # Batch size for MiniBatchKMeans
        self.color_tolerance = 0.8  # Color similarity threshold for grouping
        
        # Enhanced memory stats
        self.memory_stats.update({
            'color_groups_created': 0,
            'color_group_sizes': [],
            'color_processing_time': 0,
            'total_comparisons_saved': 0
        })
    
    def deduplicate_with_color_prefiltering(
        self, 
        image_paths: List[str], 
        output_dir: str,
        progress_callback: Optional[callable] = None
    ) -> Tuple[List[List[str]], Dict[Tuple[str, str], float]]:
        """
        Perform color-optimized deduplication with pre-grouping.
        
        This approach:
        1. Groups images by color similarity first
        2. Applies deduplication pipeline within each color group
        3. Significantly reduces computational complexity
        
        Args:
            image_paths: List of image paths to deduplicate
            output_dir: Output directory for results
            progress_callback: Optional callback for progress updates
            
        Returns:
            Tuple of (duplicate_groups, similarity_scores)
        """
        logger.info("üöÄ Starting Color-Optimized Deduplication Pipeline...")
        logger.info(f"üìä Processing {len(image_paths)} images with color pre-grouping")
        
        if not image_paths:
            logger.warning("Empty image list provided")
            return [], {}
        
        os.makedirs(output_dir, exist_ok=True)
        total_start_time = time.time()
        similarity_scores = {}
        
        # Stage 0: Color-based pre-grouping (NEW OPTIMIZATION)
        logger.info("üîÑ Stage 0: Color-based pre-grouping...")
        stage0_start = time.time()
        
        color_groups = self._stage0_color_pre_grouping(image_paths, progress_callback)
        self._log_memory_usage("Stage 0 - Color Pre-grouping")
        
        stage0_time = time.time() - stage0_start
        self.memory_stats['color_processing_time'] = stage0_time
        self.memory_stats['color_groups_created'] = len(color_groups)
        
        logger.info(f"‚úÖ Stage 0 completed in {stage0_time:.1f}s - {len(color_groups)} color groups")
        logger.info(f"üìä Color group sizes: min={min(len(g) for g in color_groups)}, max={max(len(g) for g in color_groups)}")
        
        # Process each color group independently
        all_final_groups = []
        total_comparisons = 0
        
        for i, color_group in enumerate(color_groups):
            if len(color_group) <= 1:
                all_final_groups.append(color_group)
                continue
                
            logger.info(f"üîÑ Processing color group {i+1}/{len(color_groups)} ({len(color_group)} images)")
            
            # Apply the full deduplication pipeline within this color group
            group_groups, group_scores = self._deduplicate_within_color_group(
                color_group, similarity_scores, progress_callback
            )
            
            all_final_groups.extend(group_groups)
            similarity_scores.update(group_scores)
            
            # Calculate comparisons saved
            original_comparisons = len(color_group) * (len(color_group) - 1) // 2
            total_comparisons += original_comparisons
            
            # Force garbage collection after each color group
            gc.collect()
        
        self.memory_stats['total_comparisons_saved'] = total_comparisons
        
        # Generate final report
        total_time = time.time() - total_start_time
        logger.info(f"üéâ Color-optimized deduplication completed in {total_time:.1f}s")
        logger.info(f"üìä Final results: {len(all_final_groups)} groups from {len(image_paths)} images")
        
        return all_final_groups, similarity_scores
    
    def _stage0_color_pre_grouping(
        self, 
        image_paths: List[str], 
        progress_callback: Optional[callable] = None
    ) -> List[List[str]]:
        """
        Stage 0: Group images by color similarity using MiniBatchKMeans clustering.
        
        This stage creates color-based subgroups that will be processed independently,
        significantly reducing the computational complexity of subsequent stages.
        
        Args:
            image_paths: List of image paths to group
            progress_callback: Optional callback for progress updates
            
        Returns:
            List of color-based groups, each containing similar images
        """
        logger.info(f"üé® Extracting color features for {len(image_paths)} images...")
        
        # Extract color features for all images
        color_features = {}
        valid_paths = []
        
        for i, path in enumerate(image_paths):
            try:
                # Try to get cached color features first
                if self.feature_cache and path in self.feature_cache:
                    cached_features = self.feature_cache.get_features(path)
                    if cached_features and 'color_histogram' in cached_features:
                        color_features[path] = cached_features['color_histogram']
                        valid_paths.append(path)
                        continue
                
                # Extract color features if not cached
                color_vec = self._extract_compact_color_features(path)
                if color_vec is not None:
                    color_features[path] = color_vec
                    valid_paths.append(path)
                    
                    # Cache the color features
                    if self.feature_cache:
                        self.feature_cache.put_features(path, {'color_histogram': color_vec})
                
                # Progress update
                if progress_callback and i % 100 == 0:
                    progress_callback(f"Extracting color features: {i+1}/{len(image_paths)}")
                    
            except Exception as e:
                logger.warning(f"Failed to extract color features for {path}: {e}")
                continue
        
        if not color_features:
            logger.warning("No valid color features extracted")
            return [image_paths]  # Fallback to single group
        
        logger.info(f"‚úÖ Extracted color features for {len(valid_paths)} images")
        
        # Convert to numpy array for clustering
        feature_vectors = np.array([color_features[path] for path in valid_paths])
        
        # Determine optimal number of clusters based on dataset size
        n_clusters = min(self.color_clusters, len(valid_paths) // 10)
        n_clusters = max(n_clusters, 1)  # At least 1 cluster
        
        logger.info(f"üéØ Clustering {len(feature_vectors)} images into {n_clusters} color groups...")
        
        # Perform MiniBatchKMeans clustering
        try:
            kmeans = MiniBatchKMeans(
                n_clusters=n_clusters,
                batch_size=self.batch_size,
                random_state=42,
                n_init=3
            )
            cluster_labels = kmeans.fit_predict(feature_vectors)
            
            # Group images by cluster label
            color_groups = defaultdict(list)
            for path, label in zip(valid_paths, cluster_labels):
                color_groups[label].append(path)
            
            # Convert to list and filter out empty groups
            result_groups = [group for group in color_groups.values() if group]
            
            # Sort groups by size for better processing order
            result_groups.sort(key=len, reverse=True)
            
            logger.info(f"‚úÖ Color clustering completed successfully")
            logger.info(f"üìä Group size distribution:")
            for i, group in enumerate(result_groups[:5]):  # Show first 5 groups
                logger.info(f"   Group {i+1}: {len(group)} images")
            if len(result_groups) > 5:
                logger.info(f"   ... and {len(result_groups) - 5} more groups")
            
            return result_groups
            
        except Exception as e:
            logger.error(f"Color clustering failed: {e}")
            logger.info("Falling back to single group processing")
            return [image_paths]
    
    def _extract_compact_color_features(self, image_path: str) -> Optional[np.ndarray]:
        """
        Extract compact color features for an image.
        
        Uses a combination of:
        1. Reduced color histogram (4x4x4 = 64 bins)
        2. Dominant colors extraction
        3. Efficient image loading and processing
        
        Args:
            image_path: Path to the image file
            
        Returns:
            Compact color feature vector or None if extraction fails
        """
        try:
            # Load image efficiently (downsample for speed)
            img = self._load_image_efficiently(image_path)
            if img is None:
                return None
            
            # Convert to RGB if needed
            if len(img.shape) == 3 and img.shape[2] == 4:
                img = img[:, :, :3]
            elif len(img.shape) == 2:
                # Handle grayscale images
                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
            
            # Method 1: Compact color histogram (4x4x4 = 64 bins)
            hist = cv2.calcHist([img], [0, 1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256])
            hist = cv2.normalize(hist, hist).flatten()
            
            # Method 2: Dominant colors (3 colors with weights)
            img_small = cv2.resize(img, (32, 32))  # Further downsample for efficiency
            pixels = img_small.reshape(-1, 3)
            
            # Use mini-batch K-means for dominant colors
            try:
                kmeans = MiniBatchKMeans(n_clusters=3, random_state=42, batch_size=100)
                kmeans.fit(pixels)
                
                # Get dominant colors and their weights
                colors = kmeans.cluster_centers_
                counts = np.bincount(kmeans.labels_)
                weights = counts / counts.sum()
                
                # Combine histogram and dominant colors
                dominant_features = np.concatenate([colors.flatten(), weights])
                combined_features = np.concatenate([hist, dominant_features])
                
                return combined_features
                
            except Exception as e:
                logger.debug(f"Dominant colors extraction failed: {e}")
                # Fallback to histogram only
                return hist
                
        except Exception as e:
            logger.debug(f"Color feature extraction failed for {image_path}: {e}")
            return None
    
    def _load_image_efficiently(self, image_path: str) -> Optional[np.ndarray]:
        """
        Load image efficiently with error handling and memory management.
        
        Args:
            image_path: Path to the image file
            
        Returns:
            Loaded image as numpy array or None if loading fails
        """
        try:
            # For Azure paths, use the existing Azure loading mechanism
            if 'azure' in image_path.lower() or 'blob' in image_path.lower():
                # Use existing Azure loading logic
                return self._load_azure_image(image_path)
            
            # For local files, use OpenCV
            if os.path.exists(image_path):
                img = cv2.imread(image_path)
                if img is not None:
                    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            return None
            
        except Exception as e:
            logger.debug(f"Image loading failed for {image_path}: {e}")
            return None
    
    def _deduplicate_within_color_group(
        self, 
        color_group: List[str], 
        similarity_scores: Dict[Tuple[str, str], float],
        progress_callback: Optional[callable] = None
    ) -> Tuple[List[List[str]], Dict[Tuple[str, str], float]]:
        """
        Apply the full deduplication pipeline within a color group.
        
        This method uses the existing memory-efficient pipeline but with
        optimized thresholds based on color similarity.
        
        Args:
            color_group: List of image paths in the same color group
            similarity_scores: Dictionary to store similarity scores
            progress_callback: Optional callback for progress updates
            
        Returns:
            Tuple of (duplicate_groups, similarity_scores)
        """
        logger.info(f"üîç Applying deduplication pipeline to color group ({len(color_group)} images)")
        
        # Use the existing memory-efficient pipeline but with color-optimized thresholds
        # Since images are already color-similar, we can be more lenient with other features
        
        # Stage 1: Wavelet grouping within color group
        wavelet_groups = self._stage1_wavelet_grouping(color_group, progress_callback)
        
        # Stage 2: Color verification (skip since we're already in color groups)
        # Just pass through the wavelet groups
        color_verified_groups = wavelet_groups
        
        # Stage 3: Global feature refinement with color-optimized thresholds
        global_groups = []
        for group in color_verified_groups:
            if len(group) <= 1:
                global_groups.append(group)
                continue
            
            # Use more lenient thresholds for color-similar images
            refined = self._refine_group_with_global_features_color_optimized(group)
            global_groups.extend(refined)
        
        # Stage 4: Local feature verification with color-optimized thresholds
        local_groups = []
        for group in global_groups:
            if len(group) <= 1:
                local_groups.append(group)
                continue
            
            # Use more lenient thresholds for color-similar images
            verified = self._verify_group_with_local_features_color_optimized(group)
            local_groups.extend(verified)
        
        # Stage 5: Quality-based organization
        final_groups = []
        for group in local_groups:
            if len(group) <= 1:
                final_groups.append(group)
                continue
            
            # Select best image from each group
            best_group = self._select_best_images_from_group(group)
            final_groups.append(best_group)
        
        return final_groups, similarity_scores
    
    def _refine_group_with_global_features_color_optimized(self, group: List[str]) -> List[List[str]]:
        """
        Refine group using global features with color-optimized thresholds.
        
        Since images are already color-similar, we use more lenient thresholds
        for global feature similarity.
        
        Args:
            group: List of image paths to refine
            
        Returns:
            List of refined subgroups
        """
        try:
            # Use more lenient thresholds for color-similar images
            # Original threshold might be 0.7, we'll use 0.6 for color groups
            color_optimized_threshold = 0.6  # More lenient than default
            
            # Load global features for the group
            group_features = {}
            for path in group:
                if self.feature_cache and path in self.feature_cache:
                    cached = self.feature_cache.get_features(path)
                    if cached and 'global_features' in cached:
                        group_features[path] = cached['global_features']
                        continue
                
                # Extract global features if not cached
                try:
                    features = self._extract_global_features(path)
                    if features is not None:
                        group_features[path] = features
                        # Cache the features
                        if self.feature_cache:
                            self.feature_cache.put_features(path, {'global_features': features})
                except Exception as e:
                    logger.debug(f"Failed to extract global features for {path}: {e}")
                    continue
            
            if len(group_features) < 2:
                return [group]  # Not enough features to refine
            
            # Apply color-optimized global feature refinement
            refined_groups = self._apply_global_refinement_with_threshold(
                group, group_features, color_optimized_threshold
            )
            
            return refined_groups
            
        except Exception as e:
            logger.warning(f"Global feature refinement failed: {e}")
            return [group]  # Return original group on failure
    
    def _verify_group_with_local_features_color_optimized(self, group: List[str]) -> List[List[str]]:
        """
        Verify group using local features with color-optimized thresholds.
        
        Args:
            group: List of image paths to verify
            
        Returns:
            List of verified subgroups
        """
        try:
            # Use more lenient thresholds for color-similar images
            color_optimized_threshold = 0.65  # More lenient than default
            
            # Load local features for the group
            group_features = {}
            for path in group:
                if self.feature_cache and path in self.feature_cache:
                    cached = self.feature_cache.get_features(path)
                    if cached and 'local_features' in cached:
                        group_features[path] = cached['local_features']
                        continue
                
                # Extract local features if not cached
                try:
                    features = self._extract_local_features(path)
                    if features is not None:
                        group_features[path] = features
                        # Cache the features
                        if self.feature_cache:
                            self.feature_cache.put_features(path, {'local_features': features})
                except Exception as e:
                    logger.debug(f"Failed to extract local features for {path}: {e}")
                    continue
            
            if len(group_features) < 2:
                return [group]  # Not enough features to verify
            
            # Apply color-optimized local feature verification
            verified_groups = self._apply_local_verification_with_threshold(
                group, group_features, color_optimized_threshold
            )
            
            return verified_groups
            
        except Exception as e:
            logger.warning(f"Local feature verification failed: {e}")
            return [group]  # Return original group on failure
    
    def _extract_global_features(self, image_path: str) -> Optional[np.ndarray]:
        """Extract global features for an image."""
        try:
            # Use existing feature extraction logic
            if hasattr(self, 'feature_extractor'):
                return self.feature_extractor.extract_global_features(image_path)
            else:
                # Fallback to basic feature extraction
                return self._basic_global_feature_extraction(image_path)
        except Exception as e:
            logger.debug(f"Global feature extraction failed: {e}")
            return None
    
    def _extract_local_features(self, image_path: str) -> Optional[np.ndarray]:
        """Extract local features for an image."""
        try:
            # Use existing feature extraction logic
            if hasattr(self, 'feature_extractor'):
                return self.feature_extractor.extract_local_features(image_path)
            else:
                # Fallback to basic feature extraction
                return self._basic_local_feature_extraction(image_path)
        except Exception as e:
            logger.debug(f"Local feature extraction failed: {e}")
            return None
    
    def _basic_global_feature_extraction(self, image_path: str) -> Optional[np.ndarray]:
        """Basic global feature extraction fallback."""
        try:
            img = self._load_image_efficiently(image_path)
            if img is None:
                return None
            
            # Simple global features: mean color, std color, edge density
            mean_color = np.mean(img, axis=(0, 1))
            std_color = np.std(img, axis=(0, 1))
            
            # Edge detection
            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 100, 200)
            edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])
            
            return np.concatenate([mean_color, std_color, [edge_density]])
            
        except Exception as e:
            logger.debug(f"Basic global feature extraction failed: {e}")
            return None
    
    def _basic_local_feature_extraction(self, image_path: str) -> Optional[np.ndarray]:
        """Basic local feature extraction fallback."""
        try:
            img = self._load_image_efficiently(image_path)
            if img is None:
                return None
            
            # Simple local features: SIFT-like keypoints
            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            
            # Use ORB for keypoints (faster than SIFT)
            orb = cv2.ORB_create(nfeatures=100)
            keypoints, descriptors = orb.detectAndCompute(gray, None)
            
            if descriptors is None or len(descriptors) == 0:
                # Fallback to basic features
                return np.zeros(128, dtype=np.float32)
            
            # Use mean descriptor if multiple keypoints
            if len(descriptors) > 1:
                return np.mean(descriptors, axis=0).astype(np.float32)
            else:
                return descriptors[0].astype(np.float32)
                
        except Exception as e:
            logger.debug(f"Basic local feature extraction failed: {e}")
            return None
    
    def _apply_global_refinement_with_threshold(
        self, 
        group: List[str], 
        features: Dict[str, np.ndarray], 
        threshold: float
    ) -> List[List[str]]:
        """Apply global feature refinement with custom threshold."""
        # Implementation would use the existing refinement logic
        # but with the color-optimized threshold
        # For now, return the group as-is
        return [group]
    
    def _apply_local_verification_with_threshold(
        self, 
        group: List[str], 
        features: Dict[str, np.ndarray], 
        threshold: float
    ) -> List[List[str]]:
        """Apply local feature verification with custom threshold."""
        # Implementation would use the existing verification logic
        # but with the color-optimized threshold
        # For now, return the group as-is
        return [group]
    
    def _select_best_images_from_group(self, group: List[str]) -> List[str]:
        """Select best images from a group based on quality scores."""
        try:
            # Get quality scores for all images in the group
            quality_scores = {}
            for path in group:
                if self.feature_cache and path in self.feature_cache:
                    cached = self.feature_cache.get_features(path)
                    if cached and 'quality_score' in cached:
                        quality_scores[path] = cached['quality_score']
                        continue
                
                # Extract quality score if not cached
                try:
                    score = self._extract_quality_score(path)
                    if score is not None:
                        quality_scores[path] = score
                        # Cache the score
                        if self.feature_cache:
                            self.feature_cache.put_features(path, {'quality_score': score})
                except Exception as e:
                    logger.debug(f"Failed to extract quality score for {path}: {e}")
                    continue
            
            if not quality_scores:
                return [group[0]]  # Return first image if no quality scores
            
            # Select image with highest quality score
            best_image = max(quality_scores.items(), key=lambda x: x[1])[0]
            return [best_image]
            
        except Exception as e:
            logger.warning(f"Best image selection failed: {e}")
            return [group[0]]  # Return first image on failure
    
    def _extract_quality_score(self, image_path: str) -> Optional[float]:
        """Extract quality score for an image."""
        try:
            # Use existing quality score extraction logic
            if hasattr(self, 'feature_extractor'):
                return self.feature_extractor.extract_quality_score(image_path)
            else:
                # Fallback to basic quality assessment
                return self._basic_quality_assessment(image_path)
        except Exception as e:
            logger.debug(f"Quality score extraction failed: {e}")
            return None
    
    def _basic_quality_assessment(self, image_path: str) -> Optional[float]:
        """Basic image quality assessment fallback."""
        try:
            img = self._load_image_efficiently(image_path)
            if img is None:
                return None
            
            # Simple quality metrics
            # 1. Sharpness (Laplacian variance)
            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            sharpness = np.var(laplacian)
            
            # 2. Contrast (standard deviation)
            contrast = np.std(gray)
            
            # 3. Brightness (mean)
            brightness = np.mean(gray)
            
            # 4. Noise (high-frequency content)
            kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])
            noise = cv2.filter2D(gray, -1, kernel)
            noise_level = np.std(noise)
            
            # Combine metrics into a quality score (0-100)
            quality_score = (
                min(sharpness / 1000, 30) +  # Sharpness contribution
                min(contrast / 50, 25) +      # Contrast contribution
                min(brightness / 255 * 100, 25) +  # Brightness contribution
                max(0, 20 - noise_level / 10)     # Noise penalty
            )
            
            return min(max(quality_score, 0), 100)  # Clamp to 0-100
            
        except Exception as e:
            logger.debug(f"Basic quality assessment failed: {e}")
            return None
    
    def get_color_optimization_stats(self) -> Dict[str, Any]:
        """Get statistics about color optimization performance."""
        return {
            'color_groups_created': self.memory_stats.get('color_groups_created', 0),
            'color_processing_time': self.memory_stats.get('color_processing_time', 0),
            'total_comparisons_saved': self.memory_stats.get('total_comparisons_saved', 0),
            'color_group_sizes': self.memory_stats.get('color_group_sizes', []),
            'peak_memory_mb': self.memory_stats.get('peak_memory_mb', 0),
            'memory_efficiency': self.memory_stats.get('memory_efficiency', 0)
        }


def create_color_optimized_deduplicator(
    feature_cache: Optional[BoundedFeatureCache] = None,
    **kwargs
) -> ColorOptimizedDeduplicator:
    """
    Factory function to create a color-optimized deduplicator.
    
    Args:
        feature_cache: Optional feature cache for memory efficiency
        **kwargs: Additional arguments for the deduplicator
        
    Returns:
        Configured ColorOptimizedDeduplicator instance
    """
    return ColorOptimizedDeduplicator(
        feature_cache=feature_cache,
        **kwargs
    )
